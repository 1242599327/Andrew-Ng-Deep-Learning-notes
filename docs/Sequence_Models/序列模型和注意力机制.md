<h1 align="center">序列模型和注意力机制</h1>

## Seq2Seq 模型

**Seq2Seq（Sequence-to-Sequence）**模型能够在机器翻译、语音识别等各种序列到序列的转换问题中得到应用。

一个 Seq2Seq 模型包含**编码器（Encoder）**和**解码器（Decoder）**两部分，它们通常是两个不同的 RNN。如下图所示，将编码器的输出作为解码器的输入，解码器输出正确的翻译结果。

![Seq2Seq](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Seq2Seq.png)

相关论文：

* [Sutskever et al., 2014. Sequence to sequence learning with neural networks](https://arxiv.org/pdf/1409.3215.pdf)
* [Cho et al., 2014. Learning phrase representaions using RNN encoder-decoder for statistical machine translation](https://arxiv.org/abs/1406.1078)

这种编码器-解码器的结构也可以用于图像描述（Image captioning）。将 AlexNet 作为编码器，最后一层的 Softmax 换成一个 RNN 作为解码器，网络的输出序列就是图像的一个描述。

![Image-captioning](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Image-captioning.png)

相关论文：

* [Mao et. al., 2014. Deep captioning with multimodal recurrent neural networks](https://arxiv.org/pdf/1412.6632.pdf)
* [Vinyals et. al., 2014. Show and tell: Neural image caption generator](https://arxiv.org/pdf/1411.4555.pdf)
* [Karpathy and Fei Fei, 2015. Deep visual-semantic alignments for generating image descriptions](https://arxiv.org/pdf/1412.2306.pdf)

### 选择最可能的句子

机器翻译用到的模型与语言模型相似，只是用编码器的输出作为解码器第一个时间步的输入（而非 0）。因此机器翻译的过程其实相当于建立一个条件语言模型。

由于解码器进行随机采样过程，输出的翻译结果可能有好有坏。因此需要找到能使条件概率最大化的翻译，即

$$arg \ max\_{y^{⟨1⟩}, ..., y^{⟨T\_y⟩}}P(y^{⟨1⟩}, ..., y^{⟨T\_y⟩} | x)$$

鉴于贪心搜索算法得到的结果可能不符合上述要求，解决此问题最通用的算法是**集束搜索（Beam Search）**。

## 集束搜索

**集束搜索**会考虑每个时间步多个可能的选择。设定一个**集束宽（Bean Width）**$B$，代表了解码器中每个时间步的预选单词数量。例如 $B=3$，则将第一个时间步最可能的三个预选单词及其概率值 $P(\hat y^{⟨1⟩}|x)$ 保存到计算机内存，以待后续使用。

![Beam-search](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Sequence_Models/Beam-search.png)

第二步中，分别将三个预选词作为第二个时间步的输入，得到 $P(\hat y^{⟨2⟩}|x, \hat y^{⟨1⟩})$。

因为我们需要的其实是第一个和第二个单词对，而不仅仅是第二个单词有着最大概率，因此根据条件概率公式，有：

$$P(\hat y^{⟨1⟩}, \hat y^{⟨2⟩}|x) = P(\hat y^{⟨1⟩}|x) P(\hat y^{⟨2⟩}|x, \hat y^{⟨1⟩})$$

设词典中有 $N$ 个词，则当 $B=3$ 时，有 $3*N$ 个 $P(\hat y^{⟨1⟩}, \hat y^{⟨2⟩}|x)$。仍然取其中概率值最大的 3 个，作为对应第一个词条件下的第二个词的预选词。以此类推，最后输出一个最优的结果，即结果符合公式：

$$arg \ max \prod^{T\_y}\_{t=1} P(\hat y^{⟨t⟩} | x, \hat y^{⟨1⟩}, ..., \hat y^{⟨t-1⟩})$$

可以看到，当 $B=1$ 时，集束搜索就变为贪婪搜索。

### 优化：长度标准化

**长度标准化（Length Normalization）**是对集束搜索算法的优化方式。对于公式

$$arg \ max \prod^{T\_y}\_{t=1} P(\hat y^{⟨t⟩} | x, \hat y^{⟨1⟩}, ..., \hat y^{⟨t-1⟩})$$

当多个小于 1 的概率值相乘后，会造成**数值下溢（Numerical Underflow）**，即得到的结果将会是一个电脑不能精确地表示的极小浮点数。因此，我们会取 $log$ 值，并进行标准化：

$$arg \ max \frac{1}{T\_y^{\alpha}} \sum^{T\_y}\_{t=1} logP(\hat y^{⟨t⟩} | x, \hat y^{⟨1⟩}, ..., \hat y^{⟨t-1⟩})$$

其中，$T\_y$ 是翻译结果的单词数量，$\alpha$ 是一个需要根据实际情况进行调节的超参数。标准化用于减少对输出长的结果的惩罚（因为翻译结果一般没有长度限制）。

关于集束宽 $B$ 的取值，较大的 $B$ 值意味着可能更好的结果和巨大的计算成本；而较小的 $B$ 值代表较小的计算成本和可能表现较差的结果。通常来说，$B$ 可以取一个 10 以下的值。

和 BFS、DFS 等精确的查找算法相比，集束搜索算法运行速度更快，但是不能保证一定找到 $arg \ max$ 准确的最大值。

### 误差分析

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']]}
});
</script>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=default"></script>