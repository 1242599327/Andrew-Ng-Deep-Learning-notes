<h1 align="center">浅层神经网络</h1>

## 神经网络表示

竖向堆叠起来的输入特征被称作神经网络的**输入层（the input layer）**。

神经网络的**隐藏层（a hidden layer）**。“隐藏”的含义是**在训练集中**，这些中间节点的真正数值是无法看到的。

**输出层（the output layer）**负责输出预测值。

![single_hidden_layer_neural_network](single_hidden_layer_neural_network.png)

如图是一个**双层神经网络**（或者说，**单隐层神经网络（a single hidden layer neural network）**）。当我们计算网络的层数时，通常不考虑输入层，因此图中隐藏层是第一层，输出层是第二层。

约定俗成的符号表示是：

* 输入层的激活值为$$a^{[0]}$$
* 同样，隐藏层也会产生一些激活值，记作$$a^{[1]}$$
隐藏层的第一个单元（或者说节点）就记作$$a^{[1]}_1$$输出层同理。
* 另外，隐藏层和输出层都是带有参数 W 和 b 的。它们都使用上标`[1]`来表示是和第一个隐藏层有关，或者上标`[2]`来表示是和输出层有关。

## 计算神经网络的输出

![neural_network_like_logistic](neural_network_like_logistic.png)

实际上，神经网络只不过将 Logistic 回归的计算步骤重复很多次。对于隐藏层的第一个节点，有 

$$z _1^{[1]} = (W _1^{[1]})^TX+b _1^{[1]}$$

$$a _1^{[1]} = \sigma(z _1^{[1]})$$

我们可以类推得到，对于第一个隐藏层有下列公式：

$$z^{[1]} = (W^{[1]})^Ta^{[0]}+b^{[1]}$$

$$a^{[1]} = \sigma(z^{[1]})$$

其中，`a^[0]`可以是一个列向量，也可以将多个列向量堆叠起来得到矩阵。如果是后者的话，得到的`z^[1]`和`a^[1]`也是一个矩阵。

同理，对于输出层有：

$$z^{[2]} = (W^{[2]})^Ta^{[1]}+b^{[2]}$$

$$\hat{y} = a^{[2]} = \sigma(z^{[2]})$$

## 激活函数

<p align="center">
@Kyon Huang <a href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/">首页</a> | <a href="https://github.com/bighuang624/Andrew-Ng-Deep-Learning-notes">Github</a>
</p>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=default"></script>